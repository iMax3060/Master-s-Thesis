# Bottlenecks Uncovered: A Component-Wise Breakdown of the Runtime of an OLTP System

## Abstract

Traditionally, reducing disk accesses has been more decisive to the performance of an OLTP system than reducing the number of CPU cycles needed for a given workload. It was important to keep the CPU busy&mdash;executing other transactions&mdash;while transactions had to wait for data to be fetched from hard disk. With the ever-increasing amount of available RAM in modern servers and the improved performance of NVRAM products, in-memory OLTP systems became more and more the norm. In these systems, optimizations for disk&mdash;or today SSD&mdash;accesses are much less important for regular transaction processing.

Without this performance constraining factor, minimizing the CPU cycles required to execute a transaction became the key to maximizing OLTP system throughput. To provide motivation for a complete redesign of DBMSs for these new conditions, Harizopoulos et al. identified various components of the *Shore Storage Manager* that take the vast majority of CPU cycles during the execution of some transactions of the *TPC-C* benchmark [Har+08]. They concluded that the CPU does useful work on these modern systems only in a very small portion&mdash;1 % &ndash; 2 %&mdash;of the time. In Chapter 2 of this thesis, I repeat their measurements using a different technique on a modernized successor of the *Shore Storage Manager*.

However, OLTP systems on poor hardware are still found in private and commercial applications, and they continue to be stressed with ever new workloads, so there are still opportunities for DBMS optimizations that focus on minimizing HDD or SSD access. For this reason, Chapter 1 assesses many common page replacement algorithms that have been proposed throughout history. However, it is insufficient to address only the reduction of SSD accesses in a performance evaluation of these page replacement algorithms, as some of them have the potential to become a bottleneck for a DBS. For this reason, all these algorithms have been implemented for a real DBMS and compared in terms of hit rate and *TPC-C* transaction throughput.

For my Bachelor's thesis I re-evaluated the Pointer Swizzling technique for the buffer pool that Graefe et al. proposed in [Gra+14]. However, due to stability problems of the DBMS prototype used, the measurements were hardly meaningful. A re-re-evaluation of this technique can be found in the Section 2.4.1.

- [Gra+14] Goetz Graefe et al. “In-Memory Performance for Big Data”. In: *Proceedings of the 41st International Conference on Very Large Data Bases*. Vol. 8: *Proceedings of the VLDB Endowment* (Aug. 31–Sept. 4, 2015). Ed. by Chen Li and Volker Markl. founding H. V. Jagadish. In collab. with Kevin Chang et al. Proceedings of the VLDB Endowment 1. Very Large Data Base Endowment Inc. Kohala Coast, HI, USA, Sept. 2014, pp. 37&ndash;48. ISSN: 2150-8097. DOI: [10.14778/2735461.2735465](https://doi.org/10.14778/2735461.2735465). URL: [http://www.vldb.org/pvldb/vol8/p37-graefe.pdf](http://www.vldb.org/pvldb/vol8/p37-graefe.pdf) (visited on Dec. 13, 2016).
- [Har+08] Stavros Harizopoulos et al. “OLTP through the Looking Glass, and What We Found There”. In: *Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data* (June 10–12, 2008). SIGMOD ’08. Vancouver, Canada: Association for Computing Machinery, June 2008, pp. 981&ndash;992. ISBN: 978-1-60558-102-6. DOI: [10.1145/1376616.1376713](https://doi.org/10.1145/1376616.1376713). URL: [http://nms.csail.mit.edu/~stavros/pubs/OLTP_sigmod08.pdf](http://nms.csail.mit.edu/~stavros/pubs/OLTP_sigmod08.pdf) (visited on Aug. 20, 2020).
